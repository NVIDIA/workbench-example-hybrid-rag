model_repo_path: "/model-store/"
use_ensemble: false
model_type: "MISTRAL"
backend: "trt_llm"
base_model_id: "ensemble"
prompt_timer: 60
gateway_ip: "gateway-api"
server_port_internal: 9009
customization_cache_capacity: 10000
logging_level: "INFO"
enable_chat: true
preprocessor:
  prompt_templates:
    chat: "{% set eos = '</s>' %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos + ' ' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}"
    stop_words: [</s>]
pipeline:
  model_name: "ensemble"
  num_instances: 4
trt_llm:
  use: true
  model_name: "trt_llm"
  model_type: "llama"
  ckpt_type: "hf"
  max_queue_delay_microseconds: 10000
  model_path: /model-downloads/mistral-7b-instruct-v0.1
  data_type: "float16"
  backend: "python"
  num_gpus: 1
  tensor_para_size: 1
  pipeline_para_size: 1
  max_batch_size: 4
  max_input_len: 3072
  max_output_len: 1024
  max_beam_width: 1
  int8_mode: 0
  enable_custom_all_reduce: 0
  per_column_scaling: false